{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgbm\n",
    "import xgboost as xgb\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Train = pd.read_csv('mnist_train.csv',header=None)\n",
    "Test = pd.read_csv('mnist_test.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = Train.values[:,1:]\n",
    "X_test = Test.values[:,1:]\n",
    "y_train = Train.values[:,0]\n",
    "y_test = Test.values[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del Train,Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"objective\": \"multiclass\",\n",
    "          \"boosting_type\": \"goss\",\n",
    "          \"learning_rate\": 1e-2,\n",
    "          \"num_leaves\": 16,\n",
    "          \"max_bin\": 63,\n",
    "          \"bagging_fraction\" : 0.1,\n",
    "          \"feature_fraction\": 0.3,\n",
    "          \"min_child_samples\": 50,\n",
    "          \"min_child_weight\": 50,\n",
    "          \"device_type\": \"gpu\",\n",
    "          \"gpu_use_dp\": False,\n",
    "          \"num_class\" :10 # multiclass only\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = lgbm.Dataset(X_train, y_train)\n",
    "dvalid = lgbm.Dataset(X_test, y_test, reference=dtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.987472\n",
      "[200]\tvalid_0's multi_logloss: 0.583752\n",
      "[300]\tvalid_0's multi_logloss: 0.398319\n",
      "[400]\tvalid_0's multi_logloss: 0.300727\n",
      "[500]\tvalid_0's multi_logloss: 0.242835\n",
      "[600]\tvalid_0's multi_logloss: 0.205347\n",
      "[700]\tvalid_0's multi_logloss: 0.179255\n",
      "[800]\tvalid_0's multi_logloss: 0.160742\n",
      "[900]\tvalid_0's multi_logloss: 0.146893\n",
      "[1000]\tvalid_0's multi_logloss: 0.136213\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's multi_logloss: 0.136213\n",
      "--- 316.8527974949993 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = timeit.default_timer()\n",
    "model_lgbm = lgbm.train(params, dtrain, num_boost_round=1000, valid_sets=dvalid, verbose_eval=100,\n",
    "                        early_stopping_rounds=10)\n",
    "print(\"--- %s seconds ---\" % (timeit.default_timer() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0353"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_test != model_lgbm.predict(X_test).argmax(1))/10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.98747\n",
      "[200]\tvalid_0's multi_logloss: 0.583871\n",
      "[300]\tvalid_0's multi_logloss: 0.398117\n",
      "[400]\tvalid_0's multi_logloss: 0.300764\n",
      "[500]\tvalid_0's multi_logloss: 0.242678\n",
      "[600]\tvalid_0's multi_logloss: 0.205321\n",
      "[700]\tvalid_0's multi_logloss: 0.179452\n",
      "[800]\tvalid_0's multi_logloss: 0.160736\n",
      "[900]\tvalid_0's multi_logloss: 0.146829\n",
      "[1000]\tvalid_0's multi_logloss: 0.136007\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's multi_logloss: 0.136007\n",
      "--- 70.99830526700043 seconds ---\n"
     ]
    }
   ],
   "source": [
    "params[\"device_type\"] = \"cpu\"\n",
    "start_time = timeit.default_timer()\n",
    "model_lgbm = lgbm.train(params, dtrain, num_boost_round=1000, valid_sets=dvalid, verbose_eval=100,\n",
    "                        early_stopping_rounds=10)\n",
    "print(\"--- %s seconds ---\" % (timeit.default_timer() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0353"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_test != model_lgbm.predict(X_test).argmax(1))/10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train,y_train)\n",
    "dtest = xgb.DMatrix(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "params =   {'objective':'multi:softprob',\n",
    "            'eta': 1e-2,\n",
    "            'max_leaves': 16, \n",
    "            'max_bin': 63,\n",
    "            'subsample': 0.1,\n",
    "            'colsample_bylevel': 0.3, \n",
    "            'min_child_weight':50,\n",
    "            'grow_policy': 'lossguide',\n",
    "            'tree_method':'gpu_hist',\n",
    "            'num_class': 10,\n",
    "            'eval_metric':'mlogloss'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "watchlist = [(dtest, 'eval'), (dtrain, 'train')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-mlogloss:2.284\ttrain-mlogloss:2.28417\n",
      "Multiple eval metrics have been passed: 'train-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until train-mlogloss hasn't improved in 10 rounds.\n",
      "[100]\teval-mlogloss:1.19586\ttrain-mlogloss:1.20975\n",
      "[200]\teval-mlogloss:0.779445\ttrain-mlogloss:0.79658\n",
      "[300]\teval-mlogloss:0.575178\ttrain-mlogloss:0.591336\n",
      "[400]\teval-mlogloss:0.460818\ttrain-mlogloss:0.475755\n",
      "[500]\teval-mlogloss:0.392536\ttrain-mlogloss:0.405376\n",
      "[600]\teval-mlogloss:0.349175\ttrain-mlogloss:0.360174\n",
      "[700]\teval-mlogloss:0.320426\ttrain-mlogloss:0.330032\n",
      "[800]\teval-mlogloss:0.299829\ttrain-mlogloss:0.308311\n",
      "[900]\teval-mlogloss:0.284299\ttrain-mlogloss:0.291714\n",
      "[999]\teval-mlogloss:0.2723\ttrain-mlogloss:0.278745\n",
      "--- 119.5494857499998 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = timeit.default_timer()\n",
    "model_gbm = xgb.train(params, dtrain, 1000, watchlist, early_stopping_rounds=10,verbose_eval=100)\n",
    "print(\"--- %s seconds ---\" % (timeit.default_timer() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0695"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_test != model_gbm.predict(dtest).argmax(1))/10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:10:18] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "[0]\teval-mlogloss:2.28351\ttrain-mlogloss:2.28368\n",
      "Multiple eval metrics have been passed: 'train-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until train-mlogloss hasn't improved in 10 rounds.\n",
      "[100]\teval-mlogloss:1.17383\ttrain-mlogloss:1.18571\n",
      "[200]\teval-mlogloss:0.756954\ttrain-mlogloss:0.772366\n",
      "[300]\teval-mlogloss:0.553195\ttrain-mlogloss:0.567739\n",
      "[400]\teval-mlogloss:0.440835\ttrain-mlogloss:0.453472\n",
      "[500]\teval-mlogloss:0.374354\ttrain-mlogloss:0.384899\n",
      "[600]\teval-mlogloss:0.333485\ttrain-mlogloss:0.342035\n",
      "[700]\teval-mlogloss:0.305987\ttrain-mlogloss:0.313222\n",
      "[800]\teval-mlogloss:0.286282\ttrain-mlogloss:0.292277\n",
      "[900]\teval-mlogloss:0.271579\ttrain-mlogloss:0.276535\n",
      "[999]\teval-mlogloss:0.26033\ttrain-mlogloss:0.264324\n",
      "--- 199.22793187699972 seconds ---\n"
     ]
    }
   ],
   "source": [
    "params['tree_method'] = 'hist'\n",
    "params[\"silent\"] = 1\n",
    "params['objective'] = 'multi:softprob'\n",
    "start_time = timeit.default_timer()\n",
    "model_gbm = xgb.train(params, dtrain, 1000, watchlist, early_stopping_rounds=10,verbose_eval=100)\n",
    "print(\"--- %s seconds ---\" % (timeit.default_timer() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
